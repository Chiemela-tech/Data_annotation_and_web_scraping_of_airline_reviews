{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiemela-tech/Data_annotation_and_web_scraping_of_airline_reviews/blob/main/Webscrapping_for_Reviews_on_Trustpilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmF3BmQoiFId"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base URL and total number of pages to scrape\n",
        "base_url = \"https://uk.trustpilot.com/review/www.budgetair.com?page=2\"\n",
        "total_pages = 100"
      ],
      "metadata": {
        "id": "wU10HJ9wcl9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame to store all the data\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "for page in range(1, total_pages + 1):\n",
        "    url = base_url + str(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract data for the current page\n",
        "    names = [name.text.strip() for name in soup.find_all('span', {'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'})]\n",
        "    review_counts = [count.text.strip() for count in soup.find_all('span', {'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l'})]\n",
        "    review_titles = [title.text.strip() for title in soup.find_all('h2', {'class': 'typography_heading-s__f7029 typography_appearance-default__AAY17'})]\n",
        "    review_texts = [text.text.strip() for text in soup.find_all('p', {'class': 'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'})]\n",
        "    dates = [date.text.strip() for date in soup.find_all('p', {'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17'})]\n",
        "    star_ratings = [img['alt'] for img in soup.find_all('img', {'alt': lambda x: x and 'Rated' in x})]\n",
        "\n",
        "    # Define a function to fill missing values with 'N/A'\n",
        "    def fill_missing(data, target_length):\n",
        "        return data + ['N/A'] * (target_length - len(data))\n",
        "\n",
        "    # Determine the maximum length from the extracted data\n",
        "    max_length = max(len(names), len(review_counts), len(review_titles), len(review_texts), len(dates), len(star_ratings))\n",
        "\n",
        "    # Fill missing values in each list\n",
        "    names_filled = fill_missing(names, max_length)\n",
        "    review_counts_filled = fill_missing(review_counts, max_length)\n",
        "    review_titles_filled = fill_missing(review_titles, max_length)\n",
        "    review_texts_filled = fill_missing(review_texts, max_length)\n",
        "    dates_filled = fill_missing(dates, max_length)\n",
        "    star_ratings_filled = fill_missing(star_ratings, max_length)\n",
        "\n",
        "    # Create DataFrame with filled lists\n",
        "    df_reviews_filled = pd.DataFrame({\n",
        "        'Customer Name': names_filled,\n",
        "        'Review Count': review_counts_filled,\n",
        "        'Review Title': review_titles_filled,\n",
        "        'Review Text': review_texts_filled,\n",
        "        'Date of Experience': dates_filled,\n",
        "        'Star Rating': star_ratings_filled\n",
        "    })\n",
        "\n",
        "    # Append the data from this page to the main DataFrame\n",
        "    all_data = pd.concat([all_data, df_reviews_filled], ignore_index=True)\n",
        "\n",
        "\n",
        "# Now 'all_data' contains data from all pages\n",
        "print(all_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlZhDqdnRGt",
        "outputId": "f8eed6c3-7994-4961-d466-c45586b7ccbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Customer Name Review Count  \\\n",
            "0  Unhappy Customer  77K reviews   \n",
            "1          loh sung  63K reviews   \n",
            "2            Taahir  34K reviews   \n",
            "3          Scott G.     1 review   \n",
            "4    mohinder sohal     1 review   \n",
            "\n",
            "                                        Review Title  \\\n",
            "0                                   Useless chat bot   \n",
            "1  Budget air always give the low rate but giving...   \n",
            "2                                      Great service   \n",
            "3                   Just book direct through airline   \n",
            "4                 I booked to Amritsar India and myâ€¦   \n",
            "\n",
            "                                         Review Text  \\\n",
            "0  I wanted to reschedule my flight but unable to...   \n",
            "1  Budget air always give the low rate ,but never...   \n",
            "2  Either book through the airline directly (shou...   \n",
            "3  I booked to Amritsar India and my departure wa...   \n",
            "4  I booked a return flight from London to Athens...   \n",
            "\n",
            "                   Date of Experience             Star Rating  \n",
            "0  Date of experience: 14 August 2023  Rated 1 out of 5 stars  \n",
            "1  Date of experience: 11 August 2023  Rated 1 out of 5 stars  \n",
            "2  Date of experience: 12 August 2023  Rated 5 out of 5 stars  \n",
            "3  Date of experience: 12 August 2023  Rated 3 out of 5 stars  \n",
            "4  Date of experience: 12 August 2023  Rated 1 out of 5 stars  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_text = soup.find(\"title\").get_text()\n",
        "agencyname = title_text[:31]"
      ],
      "metadata": {
        "id": "X2D9Smxg3buI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.to_excel('reviews_data.xlsx', sheet_name=agencyname, index=False)\n",
        "\n",
        "# To download the file to yoviews_data.xlsx')\n",
        "files.download('reviews_data.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZEQVNRE3XrLY",
        "outputId": "95845db0-007c-440b-baa2-6974ecd14e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b06a10c-277c-402b-bdcb-c298ad34ff84\", \"reviews_data.xlsx\", 129812)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}